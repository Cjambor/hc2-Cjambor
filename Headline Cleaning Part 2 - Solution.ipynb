{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline Cleaning Part 2: Tidying the Data\n",
    "## Solution\n",
    "---\n",
    "There are lots of ways to do things like this in Python. If you're getting good answers, don't assume there's anything wrong with your methods.\n",
    "\n",
    "---\n",
    "\n",
    "Now that we're familiar with the headline data, we're ready to _really_ clean this data up.\n",
    "\n",
    "In this workbook, we're going to make two output files. Here's what should go in them:\n",
    "* `clean_headlines.txt`: This should be a tab-delimited text file with a column for the paper, the date (in `YYYY-MM-DD` format), and the text of the headline. \n",
    "* `headline_word_count.txt`: This file should be tab-delimited with columns for the paper, the date (same format as above), each word the paper used on that date, and the count of those words. The words are defined as alphanumeric characters separated by whitespace from other characters, should have punctuation removed, and should be cast to lowercase. For example, \"Mr. Bean\" would be two words, \"mr\" and \"bean\". \n",
    "\n",
    "Let's work through an example so you can see what I mean. Here's a list of the headlines for the _Missoulian_ for 2015-09-23:\n",
    "* After EWU air raid, Bobcats switch focus to Cal Poly option\n",
    "* Alternative art gallery FrontierSpace to hold annual art auction\n",
    "* Does state gets passing grade for education funding? Group aims to find out\n",
    "* Fall films have issues\n",
    "* Family in need after Bonner fire destroyed home, killed cat\n",
    "* Headwaters Dance Company's \"last hurrah\" concerts are next week\n",
    "* Montana coaching tree gathers for fundraiser\n",
    "* Mountain Line to detour Saturday due to UM Homecoming Parade\n",
    "* Rabid bat found at picnic area north of Helena\n",
    "* Ravalli County attorney's daughter jailed in sibling assault\n",
    "* Search continues today for missing Kalispell bow hunter\n",
    "* Tester to escort Pope Francis to House chambers\n",
    "\n",
    "In `clean_headlines.txt` we'd expect to see a row that looks like this:\n",
    "Missoulian    2015-09-23    After EWU air raid, Bobcats switch focus to Cal Poly option\n",
    "\n",
    "In `headline_word_count.txt` we'd expect to see a row that looks like this:\n",
    "Missoulian    2015-09-23    after    2\n",
    "\n",
    "(Note that the gaps between fields should be a tab.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "working_dir =  \"C:\\\\Users\\\\jchan\\\\Dropbox\\\\Teaching\\\\AppliedDataAnalytics\\\\Code\\\\headline-cleaning\\\\\"\n",
    "\n",
    "input_files = [\"missoula.txt\",\"sidney.txt\",\"butte.txt\",\"bozeman.txt\",\"billings.txt\"]\n",
    "paper_names = [\"Missoulian\",\"Sidney Herald\",\"Montana Standard\",\"Bozeman Daily Chronicle\",\"Billings Gazette\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open up one of these files and see what we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_input = input_files[0]\n",
    "\n",
    "with open(working_dir + this_input) as infile :\n",
    "    for idx,row in enumerate(infile.readlines()) :\n",
    "        print(row)\n",
    "        if idx > 2 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a mess. I'm going to write a function that takes the paper in and builds a well-formatted date from these ugly dates. \n",
    "\n",
    "First, I'm just going to read in all the dates and keep them in order so that I can see what's going on. This step could be done in Excel too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = defaultdict(list) # paper keying a list of dates\n",
    "\n",
    "for this_input in input_files : # notice, by not hardcoding the input file I can quickly wrap the above cell in a `for`\n",
    "    with open(working_dir + this_input,'r',encoding=\"Latin-1\") as infile :\n",
    "        \n",
    "        these_dates = infile.readline().strip().split(\"\\t\")\n",
    "        paper = paper_names[input_files.index(this_input)] # note the use of index here. \n",
    "        \n",
    "        dates[paper] = these_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now I'm going to print the paper and the dates in \"clean\" fashion \n",
    "# to try to figure out where the 2015/2016 break is for each paper.\n",
    "for paper in dates :\n",
    "    print(paper + \" : \" + \" \".join(dates[paper]))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "# Missoulian: 23-Sep to 30-Dec are 2015. Clean split\n",
    "# Sidney: 22-Sep to 23-Dec are 2015. Clean split, barely, as 2016-09-21 is in there.\n",
    "# MT Standard: 22-Sep to 29-Dec are 2015. Clean split, barely, as 2016-09-21 is in there. \n",
    "# Bozeman: 23-Sep to 30-Dec are 2015. *NOT CLEAN SPLIT*. 28-Sep and 5-Oct are special cases of 2016.\n",
    "# Billings: 22-Sep to 30-Dec are 2015. Clean split, barely, as 2016-09-21 is in there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is a mess. The first row has all the dates, the subsequent rows have headlines with many blanks put in. Let's start by getting all the dates. We have to read all the files because we don't know if there's a date that just appears in one of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = set() # make it a set, so we don't have to keep track duplicates\n",
    "\n",
    "for this_input in input_files : # notice, by not hardcoding the input file I can quickly wrap the above cell in a `for`\n",
    "    with open(working_dir + this_input) as infile :\n",
    "        for idx,row in enumerate(infile.readlines()) :\n",
    "            these_dates = row.strip().split(\"\\t\")\n",
    "            for a_date in these_dates :\n",
    "                dates.add(a_date)\n",
    "            break # We can get out after just the first row.\n",
    "pprint(dates) # discovered a few errors when I did this the first time. Had the break in the wrong spot, for instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're in a position to write a function that takes an ugly date and makes a pretty one. We're going to need the paper as an input into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat_date(ugly_date, the_paper) :\n",
    "    '''\n",
    "        Takes as input a date of the form \"D-MMM\" and returns a date of the form\n",
    "        \"YYYY-MM-DD\". Note that we have to do some work on years. Dates in Oct, Nov,\n",
    "        Dec are *almost* all 2015. \n",
    "        \n",
    "        For every paper other than Bozeman Daily Chronicle, dates in a year\n",
    "        later than 21-Sep are in 2015. For BZN, 28-Sep and 5-Oct are in 2016.\n",
    "    '''\n",
    "    month_abbr = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "    month_num = [n+1 for n in range(12)]\n",
    "    month_str = [\"{:02d}\".format(n) for n in month_num]\n",
    "    month_lu = dict(zip(month_abbr,month_str))\n",
    "    \n",
    "    d,m = ugly_date.split(\"-\")\n",
    "    m_num = month_lu[m]\n",
    "    d_str = \"{:02d}\".format(int(d))\n",
    "    \n",
    "    if ((m == \"Sep\" and int(d) >= 22) or\n",
    "        m in [\"Oct\",\"Nov\",\"Dec\"]) :\n",
    "        y = \"2015\"\n",
    "    else :\n",
    "        y = \"2016\" \n",
    "\n",
    "    # Fix the BZN special cases. \n",
    "    if the_paper == \"Bozeman Daily Chronicle\" :\n",
    "        if ((m == \"Sep\" and d_str == \"28\") or \n",
    "            (m == \"Oct\" and d_str == \"05\")) :\n",
    "            y = \"2016\"\n",
    "\n",
    "    pretty_date = \"-\".join([y,m_num,d_str])\n",
    "    \n",
    "    return(pretty_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lots of testing here to make sure I've got what I expect.\n",
    "assert(\"2015-09-23\" == reformat_date(\"23-Sep\",\"Missoulian\"))\n",
    "assert(\"2015-09-30\" == reformat_date(\"30-Sep\",\"Missoulian\"))\n",
    "assert(\"2015-12-23\" == reformat_date(\"23-Dec\",\"Missoulian\"))\n",
    "assert(\"2016-01-06\" == reformat_date(\"6-Jan\",\"Missoulian\"))\n",
    "assert(\"2016-03-09\" == reformat_date(\"9-Mar\",\"Missoulian\"))\n",
    "assert(\"2016-06-01\" == reformat_date(\"1-Jun\",\"Missoulian\"))\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Missoulian\"))\n",
    "\n",
    "assert(\"2015-09-22\" == reformat_date(\"22-Sep\",\"Sidney Herald\"))\n",
    "assert(\"2015-09-30\" == reformat_date(\"30-Sep\",\"Sidney Herald\"))\n",
    "assert(\"2016-06-01\" == reformat_date(\"1-Jun\",\"Sidney Herald\"))\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Sidney Herald\"))\n",
    "\n",
    "assert(\"2015-09-22\" == reformat_date(\"22-Sep\",\"Montana Standard\"))\n",
    "assert(\"2015-09-30\" == reformat_date(\"30-Sep\",\"Montana Standard\"))\n",
    "assert(\"2015-10-28\" == reformat_date(\"28-Oct\",\"Montana Standard\"))\n",
    "assert(\"2016-06-01\" == reformat_date(\"1-Jun\",\"Montana Standard\"))\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Montana Standard\"))\n",
    "\n",
    "assert(\"2015-09-22\" == reformat_date(\"22-Sep\",\"Billings Gazette\"))\n",
    "assert(\"2015-09-30\" == reformat_date(\"30-Sep\",\"Billings Gazette\"))\n",
    "assert(\"2015-10-28\" == reformat_date(\"28-Oct\",\"Billings Gazette\"))\n",
    "assert(\"2016-06-01\" == reformat_date(\"1-Jun\",\"Billings Gazette\"))\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Billings Gazette\"))\n",
    "\n",
    "# Bozeman: Standard ones plus special cases\n",
    "assert(\"2015-09-23\" == reformat_date(\"23-Sep\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2015-09-30\" == reformat_date(\"30-Sep\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2015-10-28\" == reformat_date(\"28-Oct\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2016-06-01\" == reformat_date(\"1-Jun\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Bozeman Daily Chronicle\"))\n",
    "\n",
    "assert(\"2016-09-21\" == reformat_date(\"21-Sep\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2016-09-28\" == reformat_date(\"28-Sep\",\"Bozeman Daily Chronicle\"))\n",
    "assert(\"2016-10-05\" == reformat_date(\"5-Oct\",\"Bozeman Daily Chronicle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, that sucked. Okay, now let's start trying to parse these files. We'll fill up a default dictionary with the paper, the date, and then a list that has all the non-blank headlines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headline_holder = defaultdict(lambda: defaultdict(list)) # If you haven't seen this before, ask me in class. Worth discussing.\n",
    "hl_counter = 0\n",
    "\n",
    "for idx,this_input in enumerate(input_files) :     \n",
    "    with open(working_dir + this_input,'r',encoding=\"Latin-1\") as infile :\n",
    "        dates = infile.readline().strip().split(\"\\t\")\n",
    "        this_paper = paper_names[idx]\n",
    "        this_file_date_mapper = dict()\n",
    "        \n",
    "        for a_date in dates :\n",
    "            this_file_date_mapper[a_date] = reformat_date(a_date,this_paper)\n",
    "\n",
    "        # Now we've got a lookup so we can get to the real dates.\n",
    "        for headline_row in infile.readlines() :\n",
    "            potential_headlines = headline_row.strip().split(\"\\t\")\n",
    "\n",
    "            for idx, ph in enumerate(potential_headlines) : # ph stands for potential headline\n",
    "                if ph != \"\" : # gotta avoid the blanks\n",
    "                    this_ugly_date = dates[idx]\n",
    "                    this_nice_date = this_file_date_mapper[this_ugly_date]\n",
    "                    headline_holder[this_paper][this_nice_date].append(ph)\n",
    "                    hl_counter += 1\n",
    "print(\"Headlines Captured: \",hl_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(working_dir + \"clean_headlines.txt\",'w',encoding=\"UTF-8\") as ofile :\n",
    "    ofile.write(\"\\t\".join([\"paper\",\"date\",\"headline\"])+\"\\n\")\n",
    "\n",
    "    for paper in headline_holder :\n",
    "        for hl_date in headline_holder[paper] :\n",
    "            for hl in headline_holder[paper][hl_date] :\n",
    "                ofile.write(\"\\t\".join([paper, str(hl_date), hl])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets the headlines cleaned, which was a big enough chore. Now we want to clean up the headlines and do word counts. Our output data set will have paper, date, word, and count. Python makes this shockingly easy. First, let's write a function that takes a headline and returns a list of the words in lowercase with all the punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hl = \"A headline test.\"\n",
    "hl = hl.lower()\n",
    "\n",
    "clean_hl = []\n",
    "for ch in hl :\n",
    "    if ch not in excluded_chars :\n",
    "        clean_hl.append(ch)\n",
    "        \n",
    "print(\"|\".join(clean_hl))\n",
    "#print(clean_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excluded_chars = set(punctuation)\n",
    "\n",
    "for ch in [\"`\",\"‘\",\"’\"] :\n",
    "    excluded_chars.add(ch)\n",
    "\n",
    "#excluded_chars.add([\"`\",\"‘\",\"’\"]) # Thanks Levi for catching these marks\n",
    "\n",
    "def clean_headline(hl) :\n",
    "    ''' Removes punctuation, changes to lowercase, and splits on whitespace.\n",
    "        Returns a list of the words in a headline'''\n",
    "    \n",
    "    hl = hl.lower()\n",
    "    hl = ''.join([ch for ch in hl if ch not in excluded_chars])\n",
    "    return(hl.split())\n",
    "\n",
    "#clean_headline(\"This'll `test the headline    cleaner, I think 39393\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And, as always, let's test.\n",
    "assert(clean_headline(\"A headline test.\") == ['a','headline','test'])\n",
    "assert(clean_headline(\"Moar testin'.\") == ['moar','testin'])\n",
    "assert(clean_headline(\"Bobcats' woes.\") == ['bobcats','woes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count = defaultdict(\n",
    "    lambda: defaultdict(\n",
    "    lambda: defaultdict(int))) # Now we need one more level.\n",
    "\n",
    "words = set()\n",
    "\n",
    "for paper in headline_holder :\n",
    "    for hl_date in headline_holder[paper] :\n",
    "        for hl in headline_holder[paper][hl_date] :\n",
    "            word_list = clean_headline(hl)\n",
    "\n",
    "            for word in word_list:\n",
    "                words.add(word)\n",
    "                word_count[paper][hl_date][word] += 1\n",
    "\n",
    "print(\"Processed \",str(len(words)),\" words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(working_dir + \"headline_word_count.txt\",'w',encoding=\"UTF-8\") as ofile :\n",
    "    ofile.write(\"\\t\".join([\"paper\",\"date\",\"word\",\"count\"])+\"\\n\")\n",
    "\n",
    "    for paper in word_count :\n",
    "        for hl_date in word_count[paper] :\n",
    "            for word in word_count[paper][hl_date] :\n",
    "                ofile.write(\"\\t\".join([paper, hl_date,\n",
    "                                       word,\n",
    "                                       str(word_count[paper][hl_date][word])]) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
